{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38657c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import hashlib\n",
    "import threading\n",
    "import urllib.request\n",
    "from urllib.parse import urlencode, urlparse, parse_qs, urlunparse\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5487c",
   "metadata": {},
   "source": [
    "задаем параметры, которые пригодятся нам в дальнейшем:\n",
    "выход, скок будет страниц проходить, чтобы не открывал окна, ожидание загрузки, количество параллельных окон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17088b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1\"\n",
    "OUTPUT = \"links.txt\"\n",
    "MAX_PAGES = 40\n",
    "HEADLESS = True\n",
    "PAGELOAD_TIMEOUT = 20\n",
    "N_BROWSERS = 4  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a67919",
   "metadata": {},
   "source": [
    "создаем список айдишек районов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08997297",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_id = [x for x in range(1, 132)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ff87d",
   "metadata": {},
   "source": [
    "тут мы либо берем наш созданный но на всякий еще один сделали если не найден будет чтобы с верхним если че играться а так вообще можно убрать эту проверку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e2626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'district_id' in globals() and isinstance(district_id, list):\n",
    "    district_ids = district_id\n",
    "elif 'district_ids' not in globals():\n",
    "    district_ids = list(range(1, 133))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ce933",
   "metadata": {},
   "source": [
    "дальше идет подгрузка ссылок из нашего файла со ссылками проверяем содержит ли она путь и форматируем а потом в сет чтобы без дубликатов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d3fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing(path=OUTPUT) -> set[str]:\n",
    "    if not os.path.exists(path): return set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return set(ln.strip() for ln in f if ln.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1257e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_links = load_existing(OUTPUT)     \n",
    "file_lock = threading.Lock()           \n",
    "def append_threadsafe(candidates:set[str]) -> int:\n",
    "    if not candidates: return 0\n",
    "    added = 0\n",
    "    with file_lock:\n",
    "        new = [u for u in candidates if u not in seen_links]\n",
    "        if not new: return 0\n",
    "        seen_links.update(new)\n",
    "        with open(OUTPUT, \"a\", encoding=\"utf-8\") as f:\n",
    "            for u in new:\n",
    "                f.write(u + \"\\n\")\n",
    "            f.flush()\n",
    "            os.fsync(f.fileno())\n",
    "        added = len(new)\n",
    "    return added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cabcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_driver():\n",
    "    o = Options()\n",
    "    if HEADLESS: o.add_argument(\"--headless=new\")\n",
    "    o.page_load_strategy = \"eager\"\n",
    "    o.add_argument(\"--disable-gpu\")\n",
    "    o.add_argument(\"--no-sandbox\")\n",
    "    o.add_argument(\"--disable-dev-shm-usage\")\n",
    "    o.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    o.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
    "    o.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/124.0 Safari/537.36\")\n",
    "    d = webdriver.Chrome(options=o)\n",
    "    d.set_page_load_timeout(PAGELOAD_TIMEOUT)\n",
    "    d.set_script_timeout(10)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef9ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_online(timeout=4):\n",
    "    try:\n",
    "        urllib.request.urlopen(\"https://www.google.com/generate_204\", timeout=timeout)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "565922dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(drv, url, wait_css=None, attempts=4, sleep_base=1.5):\n",
    "    def restart_local_driver():\n",
    "        try: drv.quit()\n",
    "        except Exception: pass\n",
    "        return make_driver()\n",
    "\n",
    "    for i in range(1, attempts + 1):\n",
    "        t0 = time.time()\n",
    "        while not is_online():\n",
    "            if time.time() - t0 > 60:\n",
    "                raise TimeoutException(\"Сеть не восстановилась за 60 секунд.\")\n",
    "            time.sleep(1.5)\n",
    "        try:\n",
    "            drv.get(url)\n",
    "            if wait_css:\n",
    "                WebDriverWait(drv, 12).until(lambda d: len(d.find_elements(By.CSS_SELECTOR, wait_css)) > 0)\n",
    "            else:\n",
    "                time.sleep(1.2)\n",
    "            return drv\n",
    "        except (TimeoutException, WebDriverException) as e:\n",
    "            msg = str(e)\n",
    "            print(f\"[safe_get] попытка {i}/{attempts} неудачна: {msg[:140]}...\", file=sys.stderr)\n",
    "            time.sleep(sleep_base * i)\n",
    "            fatal = any(s in msg for s in [\n",
    "                \"ERR_INTERNET_DISCONNECTED\",\"ERR_NETWORK_CHANGED\",\"ERR_NAME_NOT_RESOLVED\",\n",
    "                \"disconnected: not connected to DevTools\",\"chrome not reachable\",\"timeout\"\n",
    "            ])\n",
    "            if fatal or i == attempts:\n",
    "                drv = restart_local_driver()\n",
    "    return drv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb498b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_scroll_to_bottom(driver, url_for_reload: str,\n",
    "                          max_same=3, sleep_between=2.0,\n",
    "                          js_attempts=3, kb_attempts=2):\n",
    "    def js_scroll_round():\n",
    "        nonlocal last_height, same\n",
    "        try:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(sleep_between)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            same = same + 1 if new_height == last_height else 0\n",
    "            last_height = max(last_height, new_height)\n",
    "            return True\n",
    "        except WebDriverException:\n",
    "            return False\n",
    "\n",
    "    def kb_scroll_round():\n",
    "        nonlocal same, last_height\n",
    "        try:\n",
    "            body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "            ActionChains(driver).move_to_element(body).click(body).perform()\n",
    "            for _ in range(12):\n",
    "                body.send_keys(Keys.PAGE_DOWN); time.sleep(0.12)\n",
    "            body.send_keys(Keys.END); time.sleep(sleep_between)\n",
    "            try:\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            except WebDriverException:\n",
    "                return False\n",
    "            same = same + 1 if new_h == last_height else 0\n",
    "            last_height = max(last_height, new_h)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    last_height, same = 0, 0\n",
    "    js_fail_streak = kb_fail_streak = 0\n",
    "\n",
    "    while True:\n",
    "        ok = js_scroll_round()\n",
    "        if not ok:\n",
    "            js_fail_streak += 1\n",
    "            ok2 = kb_scroll_round()\n",
    "            kb_fail_streak = 0 if ok2 else kb_fail_streak + 1\n",
    "        else:\n",
    "            js_fail_streak = 0\n",
    "\n",
    "        if js_fail_streak >= js_attempts and kb_fail_streak >= kb_attempts:\n",
    "            print(\"↻ вкладка зависла: перезапуск драйвера и повторное открытие страницы…\")\n",
    "            try: driver.quit()\n",
    "            except Exception: pass\n",
    "            driver = make_driver()\n",
    "            driver.get(url_for_reload); time.sleep(1.5)\n",
    "            last_height = same = js_fail_streak = kb_fail_streak = 0\n",
    "            continue\n",
    "\n",
    "        if same >= max_same:\n",
    "            break\n",
    "\n",
    "    time.sleep(1.1)\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42f3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url(did:int, page:int) -> str:\n",
    "    pr = urlparse(BASE); q = parse_qs(pr.query, keep_blank_values=True)\n",
    "    for k in list(q):\n",
    "        if k.startswith(\"district[\") or k == \"p\": del q[k]\n",
    "    q[\"district[0]\"] = [str(did)]\n",
    "    q[\"p\"] = [str(page)]\n",
    "    return urlunparse((pr.scheme, pr.netloc, pr.path, pr.params, urlencode(q, doseq=True), pr.fragment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "969f5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_links(driver) -> set[str]:\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, \"a[data-name='LinkArea'], a._93444fe79c--media--9P6wN\")\n",
    "    return {(c.get_attribute(\"href\") or \"\").split(\"?\")[0] for c in cards if c.get_attribute(\"href\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315dbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_district(did: int):\n",
    "    drv = make_driver()\n",
    "    total_added = 0\n",
    "    try:\n",
    "        for p in range(1, MAX_PAGES + 1):\n",
    "            url = build_url(did, p)\n",
    "            print(f\"[did {did} | p {p}] GET {url}\")\n",
    "            drv = safe_get(drv, url, wait_css=\"body\")\n",
    "            drv = safe_scroll_to_bottom(drv, url)\n",
    "            page_links = collect_links(drv)\n",
    "            added = append_threadsafe(page_links)\n",
    "            total_added += added\n",
    "            print(f\"[did {did} | p {p}] на странице: {len(page_links)} | новых ЗАПИСАНО: {added}\")\n",
    "\n",
    "            # чтобы не проверять каждую залупу котора уже есть выходим нахуй когда 0\n",
    "            if added == 0:\n",
    "                print(f\"[did {did}] новых нет → стоп по району\")\n",
    "                break\n",
    "\n",
    "            time.sleep(random.uniform(0.15, 0.35))\n",
    "    finally:\n",
    "        try: drv.quit()\n",
    "        except Exception: pass\n",
    "    return did, total_added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Старт. Уже в links.txt: 40337 ссылок.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error managing chromedriver (error decoding response body); using driver found in the cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[did 3 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=3&p=1\n",
      "[did 2 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=2&p=1\n",
      "[did 4 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=4&p=1\n",
      "[did 1 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=1&p=1\n",
      "[did 2 | p 1] на странице: 0 | новых ЗАПИСАНО: 0\n",
      "[did 2] новых нет → стоп по району\n",
      "✔ Район 2 завершён. Добавлено: 0\n",
      "[did 3 | p 1] на странице: 0 | новых ЗАПИСАНО: 0\n",
      "[did 3] новых нет → стоп по району\n",
      "✔ Район 3 завершён. Добавлено: 0\n",
      "[did 5 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=5&p=1\n",
      "[did 6 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=6&p=1\n",
      "[did 4 | p 1] на странице: 28 | новых ЗАПИСАНО: 1\n",
      "[did 4 | p 2] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=4&p=2\n",
      "[did 1 | p 1] на странице: 28 | новых ЗАПИСАНО: 1\n",
      "[did 1 | p 2] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=1&p=2\n",
      "[did 6 | p 1] на странице: 28 | новых ЗАПИСАНО: 0\n",
      "[did 6] новых нет → стоп по району\n",
      "✔ Район 6 завершён. Добавлено: 0\n",
      "[did 4 | p 2] на странице: 28 | новых ЗАПИСАНО: 2\n",
      "[did 5 | p 1] на странице: 28 | новых ЗАПИСАНО: 1\n",
      "[did 1 | p 2] на странице: 28 | новых ЗАПИСАНО: 4\n",
      "[did 4 | p 3] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=4&p=3[did 5 | p 2] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=5&p=2\n",
      "\n",
      "[did 1 | p 3] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=1&p=3\n",
      "[did 7 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=7&p=1\n",
      "[did 8 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=8&p=1\n",
      "[did 10 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=10&p=1\n",
      "[did 11 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=11&p=1\n",
      "[did 9 | p 1] GET https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&district%5B0%5D=9&p=1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Старт. Уже в {OUTPUT}: {len(seen_links)} ссылок.\\n\")\n",
    "t0 = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=N_BROWSERS) as pool:\n",
    "    futures = [pool.submit(scan_district, did) for did in district_ids]\n",
    "    for fut in as_completed(futures):\n",
    "        did, added = fut.result()\n",
    "        print(f\"✔ Район {did} завершён. Добавлено: {added}\")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nГотово. В {OUTPUT}  {len(load_existing(OUTPUT))}  ссылок.\")\n",
    "print(f\"Время: {elapsed:.1f} c. Параллельных окон: {N_BROWSERS}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cd7f5",
   "metadata": {},
   "source": [
    "тут где шард ставьте свой номер серега 2 андрей 3 барыч 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc2dcd",
   "metadata": {},
   "source": [
    "тут уже будем проходиться по каждому лоту и собирать инфу \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d8d4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKS_PATH = \"links.txt\"        \n",
    "CSV_PATH   = \"cian_flats.csv\"   \n",
    "\n",
    "WORKERS = 6                     \n",
    "BATCH_SIZE = 50                 \n",
    "TIMEOUT_WAIT = 5.5              \n",
    "TIMEOUT_PAGELOAD = 14           \n",
    "PAUSE = (0.12, 0.4)             \n",
    "\n",
    "\n",
    "SHARDS = 10   \n",
    "SHARD  = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f84f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_driver():\n",
    "    # тут настройки браузера \n",
    "    opts = Options()\n",
    "    opts.page_load_strategy = \"none\"\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--disable-notifications\")\n",
    "    opts.add_argument(\"--mute-audio\")\n",
    "    opts.add_argument(\"--disable-extensions\")\n",
    "    opts.add_argument(\"--disable-infobars\")\n",
    "    opts.add_argument(\"--window-size=1920,1080\")\n",
    "    opts.add_argument(\"--log-level=3\")\n",
    "    # нах картинки цсс шрифты чтоб интернет не пиздили \n",
    "    opts.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    prefs = {\n",
    "        \"profile.managed_default_content_settings.images\": 2,\n",
    "        \"profile.managed_default_content_settings.stylesheets\": 2,\n",
    "        \"profile.managed_default_content_settings.fonts\": 2,\n",
    "        \"profile.managed_default_content_settings.plugins\": 2,\n",
    "    }\n",
    "    opts.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "    opts.add_argument(\n",
    "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36\"\n",
    "    )\n",
    "\n",
    "    drv = webdriver.Chrome(options=opts)\n",
    "    drv.set_page_load_timeout(TIMEOUT_PAGELOAD)\n",
    "    drv.set_script_timeout(TIMEOUT_WAIT)\n",
    "\n",
    "    try:\n",
    "        drv.execute_cdp_cmd(\"Network.enable\", {})\n",
    "        drv.execute_cdp_cmd(\"Network.setBlockedURLs\", {\n",
    "            \"urls\": [\n",
    "                \"*.jpg\",\"*.jpeg\",\"*.png\",\"*.gif\",\"*.webp\",\"*.svg\",\n",
    "                \"*.mp4\",\"*.webm\",\"*.avi\",\"*.mkv\",\n",
    "                \"*.woff\",\"*.woff2\",\"*.ttf\",\"*.otf\",\n",
    "                \"*.css\",\"*.map\"\n",
    "            ]\n",
    "        })\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return drv\n",
    "\n",
    "def wait_any(drv, timeout=TIMEOUT_WAIT):\n",
    "    try:\n",
    "        WebDriverWait(drv, timeout).until(\n",
    "            EC.any_of(\n",
    "                EC.presence_of_element_located(LOCATORS[\"title\"]),\n",
    "                EC.presence_of_element_located(LOCATORS[\"price\"]),\n",
    "                EC.presence_of_element_located(LOCATORS[\"address\"])\n",
    "            )\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def open_url(drv, url):\n",
    "    try:\n",
    "        drv.get(url)\n",
    "        human_pause(0.15, 0.3)\n",
    "        try:\n",
    "            wait_any(drv, timeout=max(2.5, TIMEOUT_WAIT - 2))\n",
    "        finally:\n",
    "            try:\n",
    "                drv.execute_script(\"return window.stop && window.stop();\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        return None\n",
    "    except TimeoutException as e:\n",
    "        try:\n",
    "            drv.execute_script(\"return window.stop && window.stop();\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return f\"page_load_timeout: {e}\"\n",
    "    except WebDriverException as e:\n",
    "        return f\"webdriver_error: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"unknown_open_error: {e}\"\n",
    "\n",
    "def safe_text(drv, locator, timeout=TIMEOUT_WAIT):\n",
    "    try:\n",
    "        el = WebDriverWait(drv, timeout).until(EC.presence_of_element_located(locator))\n",
    "        return el.text.strip()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def parse_one_url(url):\n",
    "    drv = make_driver()\n",
    "    try:\n",
    "        err = open_url(drv, url)\n",
    "        data = {\"url\": url, \"_error\": err or \"\"}\n",
    "        human_pause(0.08, 0.25)\n",
    "\n",
    "        data[\"title\"]       = safe_text(drv, LOCATORS[\"title\"])\n",
    "        data[\"price\"]       = safe_text(drv, LOCATORS[\"price\"])\n",
    "        data[\"address\"]     = safe_text(drv, LOCATORS[\"address\"])\n",
    "        data[\"area\"]        = safe_text(drv, LOCATORS[\"area\"])\n",
    "        data[\"floor\"]       = safe_text(drv, LOCATORS[\"floor\"])\n",
    "        data[\"year\"]        = safe_text(drv, LOCATORS[\"year\"])\n",
    "        data[\"metro_name\"]  = safe_text(drv, LOCATORS[\"metro_name\"])\n",
    "        data[\"metro_time\"]  = safe_text(drv, LOCATORS[\"metro_time\"])\n",
    "        data[\"house_type\"]  = safe_text(drv, LOCATORS[\"house_type\"])\n",
    "\n",
    "        return data\n",
    "    finally:\n",
    "        try:\n",
    "            drv.quit()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3b42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "import time, random, csv, sys, os, hashlib\n",
    "\n",
    "LOCATORS = {\n",
    "    \"title\":   (By.XPATH, \"//h1 | //h1[contains(.,'квартира') or contains(.,'Квартира')]\"),\n",
    "    \"price\":   (By.CSS_SELECTOR, '[data-testid=\"price-amount\"] span'),\n",
    "    \"address\": (By.CSS_SELECTOR, 'div[data-name=\"AddressContainer\"]'),\n",
    "    \"area\":    (By.XPATH, \"//span[contains(text(), 'Общая площадь')]/following-sibling::span\"),\n",
    "    \"floor\":   (By.XPATH, \"//span[contains(text(), 'Этаж')]/following-sibling::span\"),\n",
    "    \"year\":    (By.XPATH, \"//span[contains(text(), 'Год постройки')]/following-sibling::span\"),\n",
    "    \"metro_name\": (By.XPATH, \"(//li[@data-name='UndergroundItem'])[1]//a[contains(@class,'underground_link')]\"),\n",
    "    \"metro_time\": (By.XPATH, \"(//li[@data-name='UndergroundItem'])[1]//span[contains(@class,'underground_time')]\"),\n",
    "    \"house_type\": (By.XPATH, \"//div[@data-name='OfferSummaryInfoItem'][.//p[contains(., 'Тип дома')]]//p[2]\")\n",
    "}\n",
    "\n",
    "CSV_KEYS = [\n",
    "    \"url\",\"title\",\"price\",\"address\",\"area\",\"floor\",\n",
    "    \"year\",\"metro_name\",\"metro_time\",\"house_type\",\"_error\"\n",
    "]\n",
    "\n",
    "def human_pause(a=PAUSE[0], b=PAUSE[1]):\n",
    "    if b > 0:\n",
    "        time.sleep(random.uniform(a, b))\n",
    "\n",
    "def stable_hash(s: str) -> int:\n",
    "    return int(hashlib.md5(s.encode(\"utf-8\")).hexdigest(), 16)\n",
    "\n",
    "def read_existing_urls(path: str) -> set:\n",
    "    seen = set()\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        return seen\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            for row in csv.DictReader(f):\n",
    "                u = (row.get(\"url\") or \"\").strip()\n",
    "                if u:\n",
    "                    seen.add(u)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return seen\n",
    "\n",
    "def save_csv_header_if_needed(path=CSV_PATH):\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.DictWriter(f, fieldnames=CSV_KEYS).writeheader()\n",
    "\n",
    "def append_csv(rows, path=CSV_PATH):\n",
    "    if not rows:\n",
    "        return\n",
    "    with open(path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=CSV_KEYS)\n",
    "        for r in rows:\n",
    "            w.writerow({k: r.get(k, \"\") for k in CSV_KEYS})\n",
    "\n",
    "def load_links(path=LINKS_PATH):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Файл {path} не найден\", file=sys.stderr)\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [ln.strip() for ln in f if ln.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd845c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущено уже записанных: 15608; осталось к обработке: 24738\n",
      "Шард 1/10: беру 1137 из 24738\n",
      "подготовлено: 1137 URL\n"
     ]
    }
   ],
   "source": [
    "links = load_links(LINKS_PATH)\n",
    "links = [u.strip() for u in links if u.strip()]\n",
    "\n",
    "links = list(dict.fromkeys(links))\n",
    "\n",
    "if not links:\n",
    "    raise SystemExit(\"Список ссылок пуст. Заполни links.txt\")\n",
    "\n",
    "# скипаем че у нас есть\n",
    "seen = read_existing_urls(CSV_PATH)\n",
    "if seen:\n",
    "    before = len(links)\n",
    "    links = [u for u in links if u not in seen]\n",
    "    print(f\"Пропущено уже записанных: {before - len(links)}; осталось к обработке: {len(links)}\")\n",
    "\n",
    "# для деления между компами\n",
    "if SHARDS > 1:\n",
    "    if not (1 <= SHARD <= SHARDS):\n",
    "        raise SystemExit(f\"Неверный SHARD={SHARD}; должен быть 1..{SHARDS}\")\n",
    "    shard_idx = SHARD - 1\n",
    "    links_sharded = [u for u in links if stable_hash(u) % SHARDS == shard_idx]\n",
    "    print(f\"Шард {SHARD}/{SHARDS}: беру {len(links_sharded)} из {len(links)}\")\n",
    "    links = links_sharded\n",
    "\n",
    "if not links:\n",
    "    raise SystemExit(\"Нечего обрабатывать — все ссылки уже в CSV или не попали в этот шард.\")\n",
    "\n",
    "save_csv_header_if_needed(CSV_PATH)\n",
    "print(f\"подготовлено: {len(links)} URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d884d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Старт: 1436 URL, воркеров=6, batch=50\n",
      "Сохранено 50/1436 (ошибок 0)\n",
      "Сохранено 100/1436 (ошибок 0)\n",
      "Сохранено 150/1436 (ошибок 0)\n",
      "Сохранено 200/1436 (ошибок 0)\n",
      "Сохранено 250/1436 (ошибок 0)\n",
      "Сохранено 300/1436 (ошибок 0)\n"
     ]
    }
   ],
   "source": [
    "done = 0\n",
    "errors = 0\n",
    "batch = []\n",
    "\n",
    "t0 = time.time()\n",
    "print(f\"Старт: {len(links)} URL, воркеров={WORKERS}, batch={BATCH_SIZE}\")\n",
    "\n",
    "try:\n",
    "    with ThreadPoolExecutor(max_workers=max(1, WORKERS)) as ex:\n",
    "        futures = {ex.submit(parse_one_url, u): u for u in links}\n",
    "        for fut in as_completed(futures):\n",
    "            url = futures[fut]\n",
    "            try:\n",
    "                row = fut.result(timeout=TIMEOUT_PAGELOAD + 12)\n",
    "                if row.get(\"_error\"):\n",
    "                    errors += 1\n",
    "            except Exception as e:\n",
    "                row = {\"url\": url, \"_error\": f\"future_error: {e}\"}\n",
    "                errors += 1\n",
    "\n",
    "            batch.append(row)\n",
    "            done += 1\n",
    "\n",
    "            if len(batch) >= BATCH_SIZE:\n",
    "                append_csv(batch, CSV_PATH)\n",
    "                batch.clear()\n",
    "                # короткий прогресс прямо в output\n",
    "                print(f\"Сохранено {done}/{len(links)} (ошибок {errors})\")\n",
    "\n",
    "finally:\n",
    "    if batch:\n",
    "        append_csv(batch, CSV_PATH)\n",
    "\n",
    "dt = time.time() - t0\n",
    "print(f\"Готово: {done} URL, ошибок {errors}. Файл -> {CSV_PATH}. Время: {dt:.1f} c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5fb9a",
   "metadata": {},
   "source": [
    "**Далее переходим к использованию API для получения дополнительных данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7376268",
   "metadata": {},
   "source": [
    "произведем геокодирование, чтобы получить координаты объектов по адресам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62bab5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных адресов к геокодингу: 6148\n",
      "Геокодировано: 100/5945\n",
      "Геокодировано: 200/5945\n",
      "Геокодировано: 300/5945\n",
      "Геокодировано: 400/5945\n",
      "Геокодировано: 500/5945\n",
      "Геокодировано: 600/5945\n",
      "Геокодировано: 700/5945\n",
      "Геокодировано: 800/5945\n",
      "Геокодировано: 900/5945\n",
      "Геокодировано: 1000/5945\n",
      "Геокодировано: 1100/5945\n",
      "Геокодировано: 1200/5945\n",
      "Геокодировано: 1300/5945\n",
      "Геокодировано: 1400/5945\n",
      "Геокодировано: 1500/5945\n",
      "Геокодировано: 1600/5945\n",
      "Геокодировано: 1700/5945\n",
      "Геокодировано: 1800/5945\n",
      "Геокодировано: 1900/5945\n",
      "Геокодировано: 2000/5945\n",
      "Геокодировано: 2100/5945\n",
      "Геокодировано: 2200/5945\n",
      "Геокодировано: 2300/5945\n",
      "Геокодировано: 2400/5945\n",
      "Геокодировано: 2500/5945\n",
      "Геокодировано: 2600/5945\n",
      "Геокодировано: 2700/5945\n",
      "Геокодировано: 2800/5945\n",
      "Геокодировано: 2900/5945\n",
      "Геокодировано: 3000/5945\n",
      "Геокодировано: 3100/5945\n",
      "Геокодировано: 3200/5945\n",
      "Геокодировано: 3300/5945\n",
      "Геокодировано: 3400/5945\n",
      "Геокодировано: 3500/5945\n",
      "Геокодировано: 3600/5945\n",
      "Геокодировано: 3700/5945\n",
      "Геокодировано: 3800/5945\n",
      "Геокодировано: 3900/5945\n",
      "Геокодировано: 4000/5945\n",
      "Геокодировано: 4100/5945\n",
      "Геокодировано: 4200/5945\n",
      "Геокодировано: 4300/5945\n",
      "Геокодировано: 4400/5945\n",
      "Геокодировано: 4500/5945\n",
      "Геокодировано: 4600/5945\n",
      "Геокодировано: 4700/5945\n",
      "Геокодировано: 4800/5945\n",
      "Геокодировано: 4900/5945\n",
      "Геокодировано: 5000/5945\n",
      "Геокодировано: 5100/5945\n",
      "Геокодировано: 5200/5945\n",
      "Геокодировано: 5300/5945\n",
      "Геокодировано: 5400/5945\n",
      "Геокодировано: 5500/5945\n",
      "Геокодировано: 5600/5945\n",
      "Геокодировано: 5700/5945\n",
      "Геокодировано: 5800/5945\n",
      "Геокодировано: 5900/5945\n",
      "Готово: cian_with_coords.csv  | заполнено координат: 24124 из 24138\n"
     ]
    }
   ],
   "source": [
    "import aiohttp, asyncio, time, random, json, os, re, pandas as pd\n",
    "\n",
    "API_KEY     = \"1ab6a9cccce94a78876a4293d15a05af\"\n",
    "INPUT_CSV   = \"cian_flats.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_coords.csv\"\n",
    "CACHE_JSON  = \"geocode_cache_geoapify.json\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "addr_col_candidates = [c for c in df.columns if c.lower() in [\"address\", \"адрес\"] or \"address\" in c.lower() or \"адрес\" in c.lower()]\n",
    "if not addr_col_candidates:\n",
    "    raise RuntimeError(\"Не нашёл колонку с адресом. Переименуй её в 'address' или укажи имя вручную.\")\n",
    "ADDR_COL = addr_col_candidates[0]\n",
    "\n",
    "def clean_address(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"\\s*на карте.*$\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "    s = s.strip(\" ,;\")\n",
    "    return s\n",
    "\n",
    "df[ADDR_COL] = df[ADDR_COL].astype(str).map(clean_address)\n",
    "\n",
    "\n",
    "cache = {}\n",
    "if os.path.exists(CACHE_JSON):\n",
    "    try:\n",
    "        cache = json.load(open(CACHE_JSON, \"r\", encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        cache = {}\n",
    "\n",
    "\n",
    "unique_addresses = (\n",
    "    df[ADDR_COL].fillna(\"\").map(str).map(str.strip)\n",
    "      .replace({\"\": pd.NA}).dropna().drop_duplicates().tolist()\n",
    ")\n",
    "\n",
    "print(f\"Уникальных адресов к геокодингу: {len(unique_addresses)}\")\n",
    "\n",
    "\n",
    "QPS = 5                 \n",
    "BURST = 10              \n",
    "FLUSH_EVERY = 200       \n",
    "\n",
    "BASE = \"https://api.geoapify.com/v1/geocode/search\"\n",
    "\n",
    "\n",
    "class TokenBucket:\n",
    "    def __init__(self, rate_per_sec:int, capacity:int):\n",
    "        self.rate = rate_per_sec\n",
    "        self.capacity = capacity\n",
    "        self.tokens = capacity\n",
    "        self.updated = time.time()\n",
    "        self.lock = asyncio.Lock()\n",
    "\n",
    "    async def take(self):\n",
    "        while True:\n",
    "            async with self.lock:\n",
    "                now = time.time()\n",
    "                # пополняем\n",
    "                delta = now - self.updated\n",
    "                self.updated = now\n",
    "                self.tokens = min(self.capacity, self.tokens + delta * self.rate)\n",
    "                if self.tokens >= 1:\n",
    "                    self.tokens -= 1\n",
    "                    return\n",
    "            await asyncio.sleep(0.02)\n",
    "\n",
    "bucket = TokenBucket(rate_per_sec=QPS, capacity=max(QPS, BURST))\n",
    "\n",
    "\n",
    "async def geocode_one(session: aiohttp.ClientSession, addr: str, attempt=0):\n",
    "\n",
    "    hit = cache.get(addr)\n",
    "    if isinstance(hit, dict) and hit.get(\"lat\") is not None and hit.get(\"lon\") is not None:\n",
    "        return hit\n",
    "\n",
    "    params = {\n",
    "        \"text\": addr,\n",
    "        \"apiKey\": API_KEY,\n",
    "        \"limit\": 1,\n",
    "\n",
    "        \"filter\": \"countrycode:ru\",\n",
    "\n",
    "        \"bias\": \"proximity:37.617635,55.755814\",\n",
    "    }\n",
    "\n",
    "    await bucket.take()  \n",
    "    try:\n",
    "        async with session.get(BASE, params=params, timeout=aiohttp.ClientTimeout(total=30)) as r:\n",
    "\n",
    "            if r.status == 429:\n",
    "                retry_after = r.headers.get(\"Retry-After\")\n",
    "                sleep_s = float(retry_after) if retry_after and retry_after.isdigit() else min(60, 2 ** attempt) + random.random()\n",
    "                await asyncio.sleep(sleep_s)\n",
    "                if attempt < 6:\n",
    "                    return await geocode_one(session, addr, attempt+1)\n",
    "                cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "                return cache[addr]\n",
    "\n",
    "            if 500 <= r.status < 600:\n",
    "                await asyncio.sleep(min(30, 2 ** attempt) + random.random())\n",
    "                if attempt < 6:\n",
    "                    return await geocode_one(session, addr, attempt+1)\n",
    "                cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "                return cache[addr]\n",
    "\n",
    "            r.raise_for_status()\n",
    "            data = await r.json()\n",
    "            feats = data.get(\"features\") or []\n",
    "            if feats:\n",
    "                lon, lat = feats[0][\"geometry\"][\"coordinates\"]\n",
    "                cache[addr] = {\"lat\": lat, \"lon\": lon}\n",
    "            else:\n",
    "                cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "            return cache[addr]\n",
    "\n",
    "    except asyncio.TimeoutError:\n",
    "        if attempt < 6:\n",
    "            await asyncio.sleep(min(30, 2 ** attempt) + random.random())\n",
    "            return await geocode_one(session, addr, attempt+1)\n",
    "        cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "        return cache[addr]\n",
    "    except aiohttp.ClientError:\n",
    "        cache[addr] = {\"lat\": None, \"lon\": None}\n",
    "        return cache[addr]\n",
    "\n",
    "\n",
    "async def run_all(addresses):\n",
    "    connector = aiohttp.TCPConnector(limit=BURST, ttl_dns_cache=300)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (geo-batch)\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    }\n",
    "    tasks = []\n",
    "    done_count = 0\n",
    "\n",
    "    async with aiohttp.ClientSession(connector=connector, headers=headers) as session:\n",
    "        sem = asyncio.Semaphore(BURST)\n",
    "\n",
    "        async def worker(a):\n",
    "            nonlocal done_count\n",
    "            async with sem:\n",
    "                res = await geocode_one(session, a)\n",
    "                done_count += 1\n",
    "\n",
    "                if done_count % FLUSH_EVERY == 0:\n",
    "                    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(cache, f, ensure_ascii=False)\n",
    "                return res\n",
    "\n",
    "        for a in addresses:\n",
    "\n",
    "            hit = cache.get(a)\n",
    "            if not (isinstance(hit, dict) and hit.get(\"lat\") is not None and hit.get(\"lon\") is not None):\n",
    "                tasks.append(asyncio.create_task(worker(a)))\n",
    "\n",
    "        if tasks:\n",
    "            for i, _ in enumerate(asyncio.as_completed(tasks), 1):\n",
    "                await _\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Геокодировано: {i}/{len(tasks)}\")\n",
    "\n",
    "\n",
    "    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache, f, ensure_ascii=False)\n",
    "\n",
    "asyncio.run(run_all(unique_addresses))\n",
    "\n",
    "\n",
    "df[\"lat\"] = df[ADDR_COL].map(lambda a: (cache.get(a) or {}).get(\"lat\"))\n",
    "df[\"lon\"] = df[ADDR_COL].map(lambda a: (cache.get(a) or {}).get(\"lon\"))\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"Готово:\", OUTPUT_CSV, \" | заполнено координат:\", df[\"lat\"].notna().sum(), \"из\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a8a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> cian_with_schools.csv | школ в bbox: 130701\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, requests\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "INPUT_CSV   = \"cian_with_coords.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_schools.csv\"\n",
    "SCHOOLS_GEOJSON = \"schools_bbox.geojson\"  # кэш скачанных школ\n",
    "RADIUS_M    = 800\n",
    "HEADERS = {\"User-Agent\": \"amenities-counter/1.1 (contact: your_email@example.com)\"}\n",
    "\n",
    "OVERPASS_URL = \"https://overpass-api.de/api/interpreter\"\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df = df[df[\"lat\"].notna() & df[\"lon\"].notna()].copy()\n",
    "\n",
    "\n",
    "min_lat, max_lat = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "min_lon, max_lon = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "\n",
    "\n",
    "lat_buf_deg = 0.02\n",
    "lon_buf_deg = 0.02 / max(0.2, math.cos(math.radians((min_lat+max_lat)/2)))\n",
    "\n",
    "min_lat_b = min_lat - lat_buf_deg\n",
    "max_lat_b = max_lat + lat_buf_deg\n",
    "min_lon_b = min_lon - lon_buf_deg\n",
    "max_lon_b = max_lon + lon_buf_deg\n",
    "\n",
    "\n",
    "if not os.path.exists(SCHOOLS_GEOJSON):\n",
    "    query = f\"\"\"\n",
    "[out:json][timeout:180];\n",
    "(\n",
    "  node[\"amenity\"=\"school\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "  way[\"amenity\"=\"school\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "  relation[\"amenity\"=\"school\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    ");\n",
    "out center;  // для ways/relations отдаёт center {{lat,lon}}\n",
    "\"\"\"\n",
    "    resp = requests.post(OVERPASS_URL, data={\"data\": query}, headers=HEADERS, timeout=300)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    with open(SCHOOLS_GEOJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "else:\n",
    "    data = json.load(open(SCHOOLS_GEOJSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "schools = []\n",
    "for el in data.get(\"elements\", []):\n",
    "    if el.get(\"type\") == \"node\":\n",
    "        lat, lon = el.get(\"lat\"), el.get(\"lon\")\n",
    "    else:\n",
    "        center = el.get(\"center\") or {}\n",
    "        lat, lon = center.get(\"lat\"), center.get(\"lon\")\n",
    "    if lat is not None and lon is not None:\n",
    "        schools.append((float(lat), float(lon)))\n",
    "\n",
    "if not schools:\n",
    "\n",
    "    df[f\"schools_count_{RADIUS_M}m\"] = 0\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"OK ->\", OUTPUT_CSV)\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sch_rad = np.radians(np.array(schools))   \n",
    "tree = BallTree(sch_rad, metric=\"haversine\")\n",
    "\n",
    "pts_rad = np.radians(df[[\"lat\",\"lon\"]].to_numpy())\n",
    "\n",
    "EARTH_M = 6371008.8\n",
    "radius_rad = RADIUS_M / EARTH_M\n",
    "\n",
    "\n",
    "ind = tree.query_radius(pts_rad, r=radius_rad, count_only=False)\n",
    "counts = np.array([len(ix) for ix in ind], dtype=int)\n",
    "\n",
    "df[f\"schools_count_{RADIUS_M}m\"] = counts\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"OK ->\", OUTPUT_CSV, \"| школ в bbox:\", len(schools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bd5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> cian_with_clinics.csv | клиник в bbox: 34115 | объектов: 24124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "INPUT_CSV   = \"cian_with_schools.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_clinics.csv\"\n",
    "CLINICS_GEOJSON = \"clinics_bbox.geojson\"  \n",
    "RADIUS_M    = 800\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"amenities-counter/1.2 (contact: nepesov82@gmail.com)\"}\n",
    "OVERPASS_URLS = [\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://z.overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.openstreetmap.ru/api/interpreter\",\n",
    "    \"https://api.openstreetmap.fr/oapi/interpreter\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "if not {\"lat\",\"lon\"}.issubset(df.columns):\n",
    "    raise ValueError(\"Нужны колонки lat и lon.\")\n",
    "df = df[df[\"lat\"].notna() & df[\"lon\"].notna()].copy()\n",
    "\n",
    "\n",
    "min_lat, max_lat = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "min_lon, max_lon = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "\n",
    "lat_buf_deg = 0.02\n",
    "lon_buf_deg = max(0.01, 0.02 / max(0.2, math.cos(math.radians((min_lat+max_lat)/2))))\n",
    "min_lat_b = min_lat - lat_buf_deg\n",
    "max_lat_b = max_lat + lat_buf_deg\n",
    "min_lon_b = min_lon - lon_buf_deg\n",
    "max_lon_b = max_lon + lon_buf_deg\n",
    "\n",
    "\n",
    "def fetch_all_clinics_bbox() -> dict:\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:180];\n",
    "    (\n",
    "      node[\"healthcare\"~\"^(clinic|medical_centre|hospital)$\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      way[\"healthcare\"~\"^(clinic|medical_centre|hospital)$\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      relation[\"healthcare\"~\"^(clinic|medical_centre|hospital)$\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "    );\n",
    "    out center;  // для ways/relations отдаёт center {{lat,lon}}\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(6):\n",
    "        for base in OVERPASS_URLS:\n",
    "            try:\n",
    "                r = requests.post(base, data={\"data\": query}, headers=HEADERS, timeout=300)\n",
    "                if r.status_code in (429, 502, 503, 504):\n",
    "                    ra = r.headers.get(\"Retry-After\")\n",
    "                    sleep_s = float(ra) if (ra and ra.isdigit()) else min(60, 2**attempt) + random.random()\n",
    "                    time.sleep(sleep_s); continue\n",
    "                r.raise_for_status()\n",
    "                return r.json()\n",
    "            except requests.RequestException as e:\n",
    "                last_err = e\n",
    "                time.sleep(min(45, 2**attempt) + random.random())\n",
    "                continue\n",
    "    raise RuntimeError(f\"Overpass не ответил: {last_err}\")\n",
    "\n",
    "if not os.path.exists(CLINICS_GEOJSON):\n",
    "    data = fetch_all_clinics_bbox()\n",
    "    with open(CLINICS_GEOJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "else:\n",
    "    data = json.load(open(CLINICS_GEOJSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "clin_pts = []\n",
    "for el in data.get(\"elements\", []):\n",
    "    if el.get(\"type\") == \"node\":\n",
    "        lat, lon = el.get(\"lat\"), el.get(\"lon\")\n",
    "    else:\n",
    "        c = el.get(\"center\") or {}\n",
    "        lat, lon = c.get(\"lat\"), c.get(\"lon\")\n",
    "    if lat is not None and lon is not None:\n",
    "        clin_pts.append((float(lat), float(lon)))\n",
    "\n",
    "\n",
    "if not clin_pts:\n",
    "    df[f\"clinics_count_{RADIUS_M}m\"] = 0\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"OK ->\", OUTPUT_CSV, \"| клиник найдено: 0\")\n",
    "    raise SystemExit\n",
    "\n",
    "clin_np = np.radians(np.array(clin_pts))  # (N,2) lat,lon в радианах\n",
    "pts_np  = np.radians(df[[\"lat\",\"lon\"]].to_numpy())\n",
    "\n",
    "EARTH_M = 6371008.8\n",
    "radius_rad = RADIUS_M / EARTH_M\n",
    "\n",
    "\n",
    "def count_with_balltree(pts_rad, ref_rad, r_rad):\n",
    "    try:\n",
    "        from sklearn.neighbors import BallTree\n",
    "        tree = BallTree(ref_rad, metric=\"haversine\")\n",
    "        ind = tree.query_radius(pts_rad, r=r_rad, count_only=False)\n",
    "        return np.array([len(ix) for ix in ind], dtype=int)\n",
    "    except Exception:\n",
    "\n",
    "        B = 5000  \n",
    "        ref_lat = ref_rad[:,0]; ref_lon = ref_rad[:,1]\n",
    "        out = np.zeros(pts_rad.shape[0], dtype=int)\n",
    "        for i in range(0, pts_rad.shape[0], B):\n",
    "            a = pts_rad[i:i+B]\n",
    "\n",
    "            dlat = a[:,[0]] - ref_lat[None,:]\n",
    "            dlon = a[:,[1]] - ref_lon[None,:]\n",
    "\n",
    "            sin_dlat = np.sin(dlat/2)\n",
    "            sin_dlon = np.sin(dlon/2)\n",
    "            aa = sin_dlat**2 + np.cos(a[:,[0]])*np.cos(ref_lat[None,:])*(sin_dlon**2)\n",
    "            dist = 2*np.arcsin(np.minimum(1, np.sqrt(aa)))  # радианы\n",
    "            out[i:i+B] = (dist <= r_rad).sum(axis=1)\n",
    "        return out\n",
    "\n",
    "counts = count_with_balltree(pts_np, clin_np, radius_rad)\n",
    "\n",
    "df[f\"clinics_count_{RADIUS_M}m\"] = counts.astype(int)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(\"OK ->\", OUTPUT_CSV, \"| клиник в bbox:\", len(clin_pts), \"| объектов:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bec9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Использую кэш: kindergartens_bbox.geojson\n",
      "Найдено детсадов: 51938\n",
      "✅ Готово → cian_with_kindergartens.csv | объектов: 24124 | детсадов: 51938\n"
     ]
    }
   ],
   "source": [
    "# сбор с детских садов \n",
    "import os, json, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "INPUT_CSV   = \"cian_with_clinics.csv\"\n",
    "OUTPUT_CSV  = \"cian_with_kindergartens.csv\"\n",
    "CACHE_JSON  = \"kindergartens_bbox.geojson\"   # кэш скачанных садиков\n",
    "RADIUS_M    = 800\n",
    "HEADERS = {\"User-Agent\": \"amenities-counter/1.3 (contact: nepesov82@gmail.com)\"}\n",
    "OVERPASS_URLS = [\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://z.overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.openstreetmap.ru/api/interpreter\",\n",
    "    \"https://api.openstreetmap.fr/oapi/interpreter\",\n",
    "]\n",
    "\n",
    "# тут коорды загружаются \n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "if not {\"lat\", \"lon\"}.issubset(df.columns):\n",
    "    raise ValueError(\"В CSV должны быть колонки lat, lon\")\n",
    "\n",
    "df = df[df[\"lat\"].notna() & df[\"lon\"].notna()].copy()\n",
    "\n",
    "min_lat, max_lat = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "min_lon, max_lon = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "lat_buf_deg = 0.02\n",
    "lon_buf_deg = max(0.01, 0.02 / max(0.2, math.cos(math.radians((min_lat+max_lat)/2))))\n",
    "\n",
    "min_lat_b = min_lat - lat_buf_deg\n",
    "max_lat_b = max_lat + lat_buf_deg\n",
    "min_lon_b = min_lon - lon_buf_deg\n",
    "max_lon_b = max_lon + lon_buf_deg\n",
    "\n",
    "def fetch_all_kindergartens() -> dict:\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:180];\n",
    "    (\n",
    "      node[\"amenity\"=\"kindergarten\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      way[\"amenity\"=\"kindergarten\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "      relation[\"amenity\"=\"kindergarten\"]({min_lat_b},{min_lon_b},{max_lat_b},{max_lon_b});\n",
    "    );\n",
    "    out center;  // для ways/relations отдаёт center {{lat,lon}}\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(6):\n",
    "        for base in OVERPASS_URLS:\n",
    "            try:\n",
    "                r = requests.post(base, data={\"data\": query}, headers=HEADERS, timeout=300)\n",
    "                if r.status_code in (429, 502, 503, 504):\n",
    "                    ra = r.headers.get(\"Retry-After\")\n",
    "                    sleep_s = float(ra) if ra and ra.isdigit() else min(60, 2**attempt) + random.random()\n",
    "                    time.sleep(sleep_s)\n",
    "                    continue\n",
    "                r.raise_for_status()\n",
    "                return r.json()\n",
    "            except requests.RequestException as e:\n",
    "                last_err = e\n",
    "                time.sleep(min(45, 2**attempt) + random.random())\n",
    "                continue\n",
    "    raise RuntimeError(f\"Overpass не ответил: {last_err}\")\n",
    "\n",
    "\n",
    "if not os.path.exists(CACHE_JSON):\n",
    "    print(\"Загружаю детские сады из Overpass...\")\n",
    "    data = fetch_all_kindergartens()\n",
    "    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "else:\n",
    "    print(\"Использую кэш:\", CACHE_JSON)\n",
    "    data = json.load(open(CACHE_JSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "kindergartens = []\n",
    "for el in data.get(\"elements\", []):\n",
    "    if el.get(\"type\") == \"node\":\n",
    "        lat, lon = el.get(\"lat\"), el.get(\"lon\")\n",
    "    else:\n",
    "        c = el.get(\"center\") or {}\n",
    "        lat, lon = c.get(\"lat\"), c.get(\"lon\")\n",
    "    if lat is not None and lon is not None:\n",
    "        kindergartens.append((float(lat), float(lon)))\n",
    "\n",
    "if not kindergartens:\n",
    "    print(\"В bbox не найдено детских садов.\")\n",
    "    df[f\"kindergartens_count_{RADIUS_M}m\"] = 0\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    exit()\n",
    "\n",
    "print(f\"Найдено детсадов: {len(kindergartens)}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "EARTH_M = 6371008.8\n",
    "radius_rad = RADIUS_M / EARTH_M\n",
    "\n",
    "pts_rad = np.radians(df[[\"lat\",\"lon\"]].to_numpy())\n",
    "kinder_rad = np.radians(np.array(kindergartens))\n",
    "\n",
    "try:\n",
    "    from sklearn.neighbors import BallTree\n",
    "    tree = BallTree(kinder_rad, metric=\"haversine\")\n",
    "    ind = tree.query_radius(pts_rad, r=radius_rad, count_only=False)\n",
    "    counts = np.array([len(i) for i in ind], dtype=int)\n",
    "except ImportError:\n",
    "    # Fallback без sklearn: векторизованный подсчёт\n",
    "    print(\"ℹ️ scikit-learn не установлен, считаю в numpy (чуть дольше)...\")\n",
    "    B = 5000\n",
    "    ref_lat, ref_lon = kinder_rad[:,0], kinder_rad[:,1]\n",
    "    counts = np.zeros(pts_rad.shape[0], dtype=int)\n",
    "    for i in range(0, pts_rad.shape[0], B):\n",
    "        a = pts_rad[i:i+B]\n",
    "        dlat = a[:,[0]] - ref_lat[None,:]\n",
    "        dlon = a[:,[1]] - ref_lon[None,:]\n",
    "        sin_dlat, sin_dlon = np.sin(dlat/2), np.sin(dlon/2)\n",
    "        aa = sin_dlat**2 + np.cos(a[:,[0]])*np.cos(ref_lat[None,:])*(sin_dlon**2)\n",
    "        dist = 2*np.arcsin(np.minimum(1, np.sqrt(aa)))\n",
    "        counts[i:i+B] = (dist <= radius_rad).sum(axis=1)\n",
    "\n",
    "df[f\"kindergartens_count_{RADIUS_M}m\"] = counts\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"Готово → {OUTPUT_CSV} | объектов: {len(df)} | детсадов: {len(kindergartens)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
